{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Переобучение нейронных сетей и борьба с ним\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZG600dQs05FM"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "def args_and_kwargs(*args, **kwargs):\n",
        "    return args, kwargs\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        layer_info = {\"type\": layer_name.strip()}\n",
        "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
        "\n",
        "        param_dict = {}\n",
        "        if len(params):\n",
        "            args, kwargs = eval(params_template)\n",
        "            if len(args) or len(kwargs):\n",
        "                param_dict[\"args\"] = args\n",
        "                for name, value in kwargs.items():\n",
        "                    param_dict[name] = value\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b84aQi2Y05FN"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-3ysaAD05FN"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LYXUajJg05FN",
        "outputId": "5c2be8fe-765e-4e11-c23e-5122bf17f4bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-19 16:14:12--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-19 16:14:13--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-19 16:14:13 (94.7 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pvA1nFwn05FN"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
        "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
        "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gFs5HPW105FO"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "aYcL28OsgSq8",
        "outputId": "87be5d4a-f507-439f-b55a-75f92a04ccb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.6MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 200kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.71MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 2')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(10 * 5 * 5, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 28, 28)\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model_task_1 = MyCNN()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "aed523e4-cb65-4015-eb53-44208289c6bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=250, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "ec1f5412-b84e-4779-88ac-d239b215cf19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "d59ebd2b-c0a2-4fdc-c5b7-63eade68cf30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/1875], Loss: 0.8111, Accuracy: 71.88%\n",
            "Epoch [1/5], Step [200/1875], Loss: 0.8385, Accuracy: 59.38%\n",
            "Epoch [1/5], Step [300/1875], Loss: 0.6619, Accuracy: 75.00%\n",
            "Epoch [1/5], Step [400/1875], Loss: 0.4865, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [500/1875], Loss: 0.5329, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [600/1875], Loss: 0.4640, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [700/1875], Loss: 0.5034, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [800/1875], Loss: 0.4303, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [900/1875], Loss: 0.3492, Accuracy: 87.50%\n",
            "Epoch [1/5], Step [1000/1875], Loss: 0.5521, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [1100/1875], Loss: 0.4234, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1200/1875], Loss: 0.6066, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1300/1875], Loss: 0.6874, Accuracy: 68.75%\n",
            "Epoch [1/5], Step [1400/1875], Loss: 0.6507, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [1500/1875], Loss: 0.5182, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [1600/1875], Loss: 0.4730, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1700/1875], Loss: 0.4732, Accuracy: 75.00%\n",
            "Epoch [1/5], Step [1800/1875], Loss: 0.4722, Accuracy: 78.12%\n",
            "Epoch [2/5], Step [100/1875], Loss: 0.4674, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [200/1875], Loss: 0.6281, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [300/1875], Loss: 0.6204, Accuracy: 68.75%\n",
            "Epoch [2/5], Step [400/1875], Loss: 0.3366, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [500/1875], Loss: 0.4149, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [600/1875], Loss: 0.3020, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [700/1875], Loss: 0.4246, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [800/1875], Loss: 0.4306, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [900/1875], Loss: 0.3157, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [1000/1875], Loss: 0.5557, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [1100/1875], Loss: 0.4618, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [1200/1875], Loss: 0.1501, Accuracy: 96.88%\n",
            "Epoch [2/5], Step [1300/1875], Loss: 0.4721, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [1400/1875], Loss: 0.2096, Accuracy: 93.75%\n",
            "Epoch [2/5], Step [1500/1875], Loss: 0.3302, Accuracy: 96.88%\n",
            "Epoch [2/5], Step [1600/1875], Loss: 0.4023, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1700/1875], Loss: 0.2143, Accuracy: 93.75%\n",
            "Epoch [2/5], Step [1800/1875], Loss: 0.3452, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [100/1875], Loss: 0.2755, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [200/1875], Loss: 0.2747, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [300/1875], Loss: 0.2029, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [400/1875], Loss: 0.5079, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [500/1875], Loss: 0.3045, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [600/1875], Loss: 0.1695, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [700/1875], Loss: 0.1841, Accuracy: 96.88%\n",
            "Epoch [3/5], Step [800/1875], Loss: 0.4740, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [900/1875], Loss: 0.2043, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1000/1875], Loss: 0.3497, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1100/1875], Loss: 0.1286, Accuracy: 96.88%\n",
            "Epoch [3/5], Step [1200/1875], Loss: 0.1730, Accuracy: 96.88%\n",
            "Epoch [3/5], Step [1300/1875], Loss: 0.3479, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1400/1875], Loss: 0.2909, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1500/1875], Loss: 0.2578, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1600/1875], Loss: 0.4568, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [1700/1875], Loss: 0.2833, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1800/1875], Loss: 0.1933, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [100/1875], Loss: 0.1944, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [200/1875], Loss: 0.3414, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [300/1875], Loss: 0.3244, Accuracy: 81.25%\n",
            "Epoch [4/5], Step [400/1875], Loss: 0.1034, Accuracy: 96.88%\n",
            "Epoch [4/5], Step [500/1875], Loss: 0.1891, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [600/1875], Loss: 0.2319, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [700/1875], Loss: 0.3818, Accuracy: 81.25%\n",
            "Epoch [4/5], Step [800/1875], Loss: 0.1892, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [900/1875], Loss: 0.2141, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1000/1875], Loss: 0.5735, Accuracy: 78.12%\n",
            "Epoch [4/5], Step [1100/1875], Loss: 0.3399, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [1200/1875], Loss: 0.1374, Accuracy: 96.88%\n",
            "Epoch [4/5], Step [1300/1875], Loss: 0.2028, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1400/1875], Loss: 0.2473, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1500/1875], Loss: 0.5503, Accuracy: 75.00%\n",
            "Epoch [4/5], Step [1600/1875], Loss: 0.2478, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1700/1875], Loss: 0.3416, Accuracy: 90.62%\n",
            "Epoch [4/5], Step [1800/1875], Loss: 0.3774, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [100/1875], Loss: 0.4046, Accuracy: 81.25%\n",
            "Epoch [5/5], Step [200/1875], Loss: 0.2141, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [300/1875], Loss: 0.2721, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [400/1875], Loss: 0.1086, Accuracy: 100.00%\n",
            "Epoch [5/5], Step [500/1875], Loss: 0.2881, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [600/1875], Loss: 0.2441, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [700/1875], Loss: 0.5182, Accuracy: 81.25%\n",
            "Epoch [5/5], Step [800/1875], Loss: 0.2194, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [900/1875], Loss: 0.1803, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [1000/1875], Loss: 0.4517, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [1100/1875], Loss: 0.1811, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1200/1875], Loss: 0.4058, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1300/1875], Loss: 0.4850, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [1400/1875], Loss: 0.1700, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1500/1875], Loss: 0.2421, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1600/1875], Loss: 0.1012, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [1700/1875], Loss: 0.3075, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1800/1875], Loss: 0.2647, Accuracy: 93.75%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001)\n",
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_1(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 5, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "1e7f3338-65c7-4747-ff03-b21ae8ce1e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.90628\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "da930c34-185b-4949-b7a4-fbdde62e9e54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8871\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibrJCBno05FR"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EwidOIly05FR",
        "outputId": "f8e89a3a-a7f4-46f1-f144-60d53de359e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjfOqpPx05FS"
      },
      "source": [
        "### Задача №2: Переобучение (Initiation)\n",
        "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
        "\n",
        "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
        "\n",
        "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE2fcyrE05FS"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче.\n",
        "\n",
        "Не используйте `Dropout` и `BatchNorm` в этой задаче"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "hW8IxBek05FS"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    # self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    # self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(28 * 28, 28 * 28)\n",
        "    self.fc4 = nn.Linear(28 * 28, 10)\n",
        "  def forward(self, x):\n",
        "    # x = x.view(-1, 1, 28, 28)\n",
        "    # x = self.pool(F.relu(self.conv1(x)))\n",
        "    # x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "model_task_2 = MyCNN()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_2.to(device)"
      ],
      "metadata": {
        "id": "6jiORYjA4Pgd",
        "outputId": "9a6c0b93-6230-4bda-df27-aad1fc9d319e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
              "  (fc4): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "id": "jprUNz1V05FS",
        "outputId": "ba17dde9-567b-479f-b188-4b06a3ccc57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [500/1875], Loss: 0.2380, Accuracy: 90.62%\n",
            "Epoch [1/1], Step [1000/1875], Loss: 0.2740, Accuracy: 90.62%\n",
            "Epoch [1/1], Step [1500/1875], Loss: 0.5060, Accuracy: 87.50%\n",
            "Epoch [2/1], Step [500/1875], Loss: 0.2204, Accuracy: 90.62%\n",
            "Epoch [2/1], Step [1000/1875], Loss: 0.3532, Accuracy: 87.50%\n",
            "Epoch [2/1], Step [1500/1875], Loss: 0.4822, Accuracy: 84.38%\n",
            "Epoch [3/1], Step [500/1875], Loss: 0.2757, Accuracy: 87.50%\n",
            "Epoch [3/1], Step [1000/1875], Loss: 0.1456, Accuracy: 96.88%\n",
            "Epoch [3/1], Step [1500/1875], Loss: 0.3662, Accuracy: 81.25%\n",
            "Epoch [4/1], Step [500/1875], Loss: 0.2013, Accuracy: 96.88%\n",
            "Epoch [4/1], Step [1000/1875], Loss: 0.1925, Accuracy: 90.62%\n",
            "Epoch [4/1], Step [1500/1875], Loss: 0.1809, Accuracy: 100.00%\n",
            "Epoch [5/1], Step [500/1875], Loss: 0.1639, Accuracy: 93.75%\n",
            "Epoch [5/1], Step [1000/1875], Loss: 0.2659, Accuracy: 90.62%\n",
            "Epoch [5/1], Step [1500/1875], Loss: 0.2196, Accuracy: 93.75%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_2.parameters(), lr=0.001)\n",
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_2(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 5, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MAAqZ2805FS"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "id": "gkkzvGzY05FS"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_2 = []\n",
        "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
        "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
        "    layers_task_2.append(layer_name)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFc0qnUJ05FS"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "b7uExL-Q05FS",
        "outputId": "a568f7ba-7355-4be6-f371-e5bf7a7d81df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.90737\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "id": "wGDdhJ0X05FS",
        "outputId": "0f1242d9-c07e-4772-d656-897e76f134a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8819\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djPttxZ005FS"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "id": "CxFDi7bk05FT",
        "outputId": "4361056b-fb60-4e64-d892-fbfc7388e950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Test accuracy should be at least 0.04 lower that train.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-427-e7c71a37d5bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtrain_acc_task_2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.88\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train accuracy must be higher than 0.88\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m assert (\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_acc_task_2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_acc_task_2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ), \"Test accuracy should be at least 0.04 lower that train.\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Test accuracy should be at least 0.04 lower that train."
          ]
        }
      ],
      "source": [
        "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
        "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert (\n",
        "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
        "), \"Test accuracy should be at least 0.04 lower that train.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP7Y8HsJ05FT"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "8Yl3AVBU05FT",
        "outputId": "b215a716-f409-4c95-c1ce-c4a66f883992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_tasks_1_and_2.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksa57VFv05FT"
      },
      "source": [
        "### Задача №3: Исправление модели (Return)\n",
        "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
        "\n",
        "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
        "\n",
        "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpHdKXKp05FT"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче.\n",
        "\n",
        "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "wN9b5Pp405FT"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert (\n",
        "    layers_task_2 is not None\n",
        "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "W9ETekkY05FT"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv0 = nn.Conv2d(1, 1, 3)\n",
        "    # self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    # self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    # self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    # self.fc1 = nn.Linear(10 * 5 * 5, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "    self.fc3 = nn.Linear(7000, 500)\n",
        "    self.bn3 = nn.BatchNorm1d(500)\n",
        "    self.fc0 = nn.Linear(28 * 28, 5000)\n",
        "    self.bn0 = nn.BatchNorm1d(5000)\n",
        "    self.fc01 = nn.Linear(5000, 7000)\n",
        "    self.bn01 = nn.BatchNorm1d(7000)\n",
        "\n",
        "    self.dp = nn.Dropout(0.3)\n",
        "    # self.fc02 = nn.Linear(10000, 250)\n",
        "  def forward(self, x):\n",
        "    x = self.m(x)\n",
        "    x = self.dp(x)\n",
        "    x = F.relu(self.bn0(self.fc0(x)))\n",
        "    x = self.dp(x)\n",
        "    x = F.relu(self.bn01(self.fc01(x)))\n",
        "    x = self.dp(x)\n",
        "    x = F.relu(self.bn3(self.fc3(x)))\n",
        "    x = self.dp(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model_task_3 = MyCNN()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_3.to(device)"
      ],
      "metadata": {
        "id": "GtWsfUfuG26R",
        "outputId": "9e508d13-7f48-43c6-debb-8cd2383b252a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (fc3): Linear(in_features=7000, out_features=500, bias=True)\n",
              "  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc0): Linear(in_features=784, out_features=5000, bias=True)\n",
              "  (bn0): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc01): Linear(in_features=5000, out_features=7000, bias=True)\n",
              "  (bn01): BatchNorm1d(7000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dp): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "dEayHdKb05FT",
        "outputId": "256e97ed-a646-436d-9e49-61dd63e19005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/1875], Loss: 0.4973, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [200/1875], Loss: 0.4546, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [300/1875], Loss: 0.3334, Accuracy: 90.62%\n",
            "Epoch [1/2], Step [400/1875], Loss: 0.2873, Accuracy: 93.75%\n",
            "Epoch [1/2], Step [500/1875], Loss: 0.5772, Accuracy: 87.50%\n",
            "Epoch [1/2], Step [600/1875], Loss: 0.3372, Accuracy: 84.38%\n",
            "Epoch [1/2], Step [700/1875], Loss: 0.1656, Accuracy: 96.88%\n",
            "Epoch [1/2], Step [800/1875], Loss: 0.4458, Accuracy: 90.62%\n",
            "Epoch [1/2], Step [900/1875], Loss: 0.5786, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [1000/1875], Loss: 0.3358, Accuracy: 93.75%\n",
            "Epoch [1/2], Step [1100/1875], Loss: 0.3558, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [1200/1875], Loss: 0.3486, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [1300/1875], Loss: 0.2152, Accuracy: 93.75%\n",
            "Epoch [1/2], Step [1400/1875], Loss: 0.6451, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [1500/1875], Loss: 0.3962, Accuracy: 81.25%\n",
            "Epoch [1/2], Step [1600/1875], Loss: 0.1570, Accuracy: 96.88%\n",
            "Epoch [1/2], Step [1700/1875], Loss: 0.3176, Accuracy: 84.38%\n",
            "Epoch [1/2], Step [1800/1875], Loss: 0.2983, Accuracy: 81.25%\n",
            "Epoch [2/2], Step [100/1875], Loss: 0.3570, Accuracy: 90.62%\n",
            "Epoch [2/2], Step [200/1875], Loss: 0.2322, Accuracy: 87.50%\n",
            "Epoch [2/2], Step [300/1875], Loss: 0.3943, Accuracy: 81.25%\n",
            "Epoch [2/2], Step [400/1875], Loss: 0.3221, Accuracy: 84.38%\n",
            "Epoch [2/2], Step [500/1875], Loss: 0.2376, Accuracy: 87.50%\n",
            "Epoch [2/2], Step [600/1875], Loss: 0.1154, Accuracy: 93.75%\n",
            "Epoch [2/2], Step [700/1875], Loss: 0.2472, Accuracy: 90.62%\n",
            "Epoch [2/2], Step [800/1875], Loss: 0.4184, Accuracy: 81.25%\n",
            "Epoch [2/2], Step [900/1875], Loss: 0.1538, Accuracy: 93.75%\n",
            "Epoch [2/2], Step [1000/1875], Loss: 0.4536, Accuracy: 84.38%\n",
            "Epoch [2/2], Step [1100/1875], Loss: 0.2904, Accuracy: 90.62%\n",
            "Epoch [2/2], Step [1200/1875], Loss: 0.4179, Accuracy: 84.38%\n",
            "Epoch [2/2], Step [1300/1875], Loss: 0.3314, Accuracy: 87.50%\n",
            "Epoch [2/2], Step [1400/1875], Loss: 0.3894, Accuracy: 84.38%\n",
            "Epoch [2/2], Step [1500/1875], Loss: 0.1514, Accuracy: 96.88%\n",
            "Epoch [2/2], Step [1600/1875], Loss: 0.2695, Accuracy: 93.75%\n",
            "Epoch [2/2], Step [1700/1875], Loss: 0.3316, Accuracy: 87.50%\n",
            "Epoch [2/2], Step [1800/1875], Loss: 0.4064, Accuracy: 87.50%\n",
            "Epoch [3/2], Step [100/1875], Loss: 0.2489, Accuracy: 84.38%\n",
            "Epoch [3/2], Step [200/1875], Loss: 0.3118, Accuracy: 90.62%\n",
            "Epoch [3/2], Step [300/1875], Loss: 0.1607, Accuracy: 93.75%\n",
            "Epoch [3/2], Step [400/1875], Loss: 0.5313, Accuracy: 84.38%\n",
            "Epoch [3/2], Step [500/1875], Loss: 0.0736, Accuracy: 96.88%\n",
            "Epoch [3/2], Step [600/1875], Loss: 0.1251, Accuracy: 93.75%\n",
            "Epoch [3/2], Step [700/1875], Loss: 0.4156, Accuracy: 84.38%\n",
            "Epoch [3/2], Step [800/1875], Loss: 0.2043, Accuracy: 93.75%\n",
            "Epoch [3/2], Step [900/1875], Loss: 0.3294, Accuracy: 81.25%\n",
            "Epoch [3/2], Step [1000/1875], Loss: 0.2037, Accuracy: 93.75%\n",
            "Epoch [3/2], Step [1100/1875], Loss: 0.1832, Accuracy: 96.88%\n",
            "Epoch [3/2], Step [1200/1875], Loss: 0.2796, Accuracy: 87.50%\n",
            "Epoch [3/2], Step [1300/1875], Loss: 0.1309, Accuracy: 93.75%\n",
            "Epoch [3/2], Step [1400/1875], Loss: 0.1874, Accuracy: 93.75%\n",
            "Epoch [3/2], Step [1500/1875], Loss: 0.2600, Accuracy: 90.62%\n",
            "Epoch [3/2], Step [1600/1875], Loss: 0.0685, Accuracy: 96.88%\n",
            "Epoch [3/2], Step [1700/1875], Loss: 0.4818, Accuracy: 81.25%\n",
            "Epoch [3/2], Step [1800/1875], Loss: 0.2433, Accuracy: 87.50%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_3.parameters(), lr=0.001)\n",
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(3):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_3(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 2, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W7L12PV05FU"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "Vs0mGR1105FU"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_3 = []\n",
        "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    layers_task_3.append(layer_name)\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for model_3_layer in layers_task_3:\n",
        "    model_2_layer = layers_task_2[idx]\n",
        "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
        "        assert (\n",
        "            model_3_layer == model_2_layer\n",
        "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
        "        idx += 1\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTJq1ur205FU"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "ZGYi48yp05FU",
        "outputId": "8f38a851-4b12-4beb-ab52-da7985988319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.92677\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "n5-2FPQf05FU",
        "outputId": "7c49648e-015e-439f-a7eb-cd55d19f0d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8831\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYg1DeJj05FU"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "qHbaPrYn05FU",
        "outputId": "81b2e30f-2cad-436f-b56a-a43c25dae14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Test accuracy should not be lower that train more than by 0.015",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-275-88ddcc79ced4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtrain_acc_task_3\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.865\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test accuracy must be higher than 0.865\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m assert (\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_acc_task_3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_acc_task_3\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.015\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ), \"Test accuracy should not be lower that train more than by 0.015\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Test accuracy should not be lower that train more than by 0.015"
          ]
        }
      ],
      "source": [
        "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
        "assert (\n",
        "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
        "), \"Test accuracy should not be lower that train more than by 0.015\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SjndVN405FU"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc4ivK1B05FU"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_final.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xai8JL3tgSq_"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
        "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
        "* `submission_dict_final.json` в задачу Return.\n",
        "\n",
        "\n",
        "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}