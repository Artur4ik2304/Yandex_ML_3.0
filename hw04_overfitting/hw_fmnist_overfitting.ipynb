{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Переобучение нейронных сетей и борьба с ним\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "ZG600dQs05FM"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "def args_and_kwargs(*args, **kwargs):\n",
        "    return args, kwargs\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        layer_info = {\"type\": layer_name.strip()}\n",
        "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
        "\n",
        "        param_dict = {}\n",
        "        if len(params):\n",
        "            args, kwargs = eval(params_template)\n",
        "            if len(args) or len(kwargs):\n",
        "                param_dict[\"args\"] = args\n",
        "                for name, value in kwargs.items():\n",
        "                    param_dict[name] = value\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "id": "b84aQi2Y05FN"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-3ysaAD05FN"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "LYXUajJg05FN",
        "outputId": "c0459048-a7bd-4c3a-8db9-65446e4d686f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-19 18:24:02--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-19 18:24:03--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-04-19 18:24:03 (85.2 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "pvA1nFwn05FN"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
        "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
        "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "gFs5HPW105FO"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "7425d70a-fed4-48b1-b249-81bdab9e2753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 7')"
            ]
          },
          "metadata": {},
          "execution_count": 435
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    self.bn1 = nn.BatchNorm2d(5)\n",
        "    self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(10)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(10 * 5 * 5, 500)\n",
        "    self.bn3 = nn.BatchNorm1d(500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    self.dp = nn.Dropout(0.2)\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 28, 28)\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = self.m(x)\n",
        "    x = self.dp(x)\n",
        "    x = F.relu(self.bn3(self.fc1(x)))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model_task_1 = MyCNN()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "2de91de2-6bc2-4ba1-fb82-e588cd0e47b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=250, out_features=500, bias=True)\n",
              "  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (dp): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 489
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 490,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "802e30c0-d069-45c1-df0e-00d4c1c42471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 491,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "1f316ecd-7e97-4ab9-8a72-54fd7c993713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/1875], Loss: 0.4310, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [200/1875], Loss: 0.5133, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [300/1875], Loss: 0.5932, Accuracy: 71.88%\n",
            "Epoch [1/5], Step [400/1875], Loss: 0.4872, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [500/1875], Loss: 0.5424, Accuracy: 68.75%\n",
            "Epoch [1/5], Step [600/1875], Loss: 0.5531, Accuracy: 71.88%\n",
            "Epoch [1/5], Step [700/1875], Loss: 0.4357, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [800/1875], Loss: 0.2687, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [900/1875], Loss: 0.3418, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1000/1875], Loss: 0.6846, Accuracy: 68.75%\n",
            "Epoch [1/5], Step [1100/1875], Loss: 0.3294, Accuracy: 81.25%\n",
            "Epoch [1/5], Step [1200/1875], Loss: 0.2781, Accuracy: 87.50%\n",
            "Epoch [1/5], Step [1300/1875], Loss: 0.3668, Accuracy: 75.00%\n",
            "Epoch [1/5], Step [1400/1875], Loss: 0.7471, Accuracy: 81.25%\n",
            "Epoch [1/5], Step [1500/1875], Loss: 0.4910, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [1600/1875], Loss: 0.3776, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1700/1875], Loss: 0.3220, Accuracy: 87.50%\n",
            "Epoch [1/5], Step [1800/1875], Loss: 0.2807, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [100/1875], Loss: 0.3932, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [200/1875], Loss: 0.3638, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [300/1875], Loss: 0.2547, Accuracy: 93.75%\n",
            "Epoch [2/5], Step [400/1875], Loss: 0.3964, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [500/1875], Loss: 0.4398, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [600/1875], Loss: 0.1333, Accuracy: 96.88%\n",
            "Epoch [2/5], Step [700/1875], Loss: 0.3768, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [800/1875], Loss: 0.3627, Accuracy: 93.75%\n",
            "Epoch [2/5], Step [900/1875], Loss: 0.3730, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1000/1875], Loss: 0.5321, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [1100/1875], Loss: 0.3907, Accuracy: 78.12%\n",
            "Epoch [2/5], Step [1200/1875], Loss: 0.4730, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1300/1875], Loss: 0.5165, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [1400/1875], Loss: 0.3553, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1500/1875], Loss: 0.6861, Accuracy: 78.12%\n",
            "Epoch [2/5], Step [1600/1875], Loss: 0.5153, Accuracy: 75.00%\n",
            "Epoch [2/5], Step [1700/1875], Loss: 0.4446, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1800/1875], Loss: 0.3477, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [100/1875], Loss: 0.2464, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [200/1875], Loss: 0.3482, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [300/1875], Loss: 0.3727, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [400/1875], Loss: 0.4363, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [500/1875], Loss: 0.1644, Accuracy: 96.88%\n",
            "Epoch [3/5], Step [600/1875], Loss: 0.3548, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [700/1875], Loss: 0.6693, Accuracy: 71.88%\n",
            "Epoch [3/5], Step [800/1875], Loss: 0.4375, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [900/1875], Loss: 0.1593, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1000/1875], Loss: 0.2707, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1100/1875], Loss: 0.3553, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1200/1875], Loss: 0.2712, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1300/1875], Loss: 0.2053, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1400/1875], Loss: 0.2252, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1500/1875], Loss: 0.1105, Accuracy: 100.00%\n",
            "Epoch [3/5], Step [1600/1875], Loss: 0.5581, Accuracy: 78.12%\n",
            "Epoch [3/5], Step [1700/1875], Loss: 0.5009, Accuracy: 84.38%\n",
            "Epoch [3/5], Step [1800/1875], Loss: 0.4896, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [100/1875], Loss: 0.5212, Accuracy: 78.12%\n",
            "Epoch [4/5], Step [200/1875], Loss: 0.2866, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [300/1875], Loss: 0.2282, Accuracy: 90.62%\n",
            "Epoch [4/5], Step [400/1875], Loss: 0.5715, Accuracy: 78.12%\n",
            "Epoch [4/5], Step [500/1875], Loss: 0.5325, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [600/1875], Loss: 0.2541, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [700/1875], Loss: 0.2351, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [800/1875], Loss: 0.2198, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [900/1875], Loss: 0.2295, Accuracy: 90.62%\n",
            "Epoch [4/5], Step [1000/1875], Loss: 0.4433, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [1100/1875], Loss: 0.3252, Accuracy: 81.25%\n",
            "Epoch [4/5], Step [1200/1875], Loss: 0.3585, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [1300/1875], Loss: 0.2039, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [1400/1875], Loss: 0.1755, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1500/1875], Loss: 0.2460, Accuracy: 90.62%\n",
            "Epoch [4/5], Step [1600/1875], Loss: 0.3060, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [1700/1875], Loss: 0.4241, Accuracy: 81.25%\n",
            "Epoch [4/5], Step [1800/1875], Loss: 0.2952, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [100/1875], Loss: 0.2303, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [200/1875], Loss: 0.4911, Accuracy: 78.12%\n",
            "Epoch [5/5], Step [300/1875], Loss: 0.3599, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [400/1875], Loss: 0.1943, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [500/1875], Loss: 0.3117, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [600/1875], Loss: 0.6341, Accuracy: 75.00%\n",
            "Epoch [5/5], Step [700/1875], Loss: 0.3364, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [800/1875], Loss: 0.1877, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [900/1875], Loss: 0.1924, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1000/1875], Loss: 0.1219, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [1100/1875], Loss: 0.2132, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [1200/1875], Loss: 0.3519, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1300/1875], Loss: 0.3215, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [1400/1875], Loss: 0.1531, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [1500/1875], Loss: 0.3737, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [1600/1875], Loss: 0.4289, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1700/1875], Loss: 0.1254, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [1800/1875], Loss: 0.2594, Accuracy: 90.62%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001)\n",
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_1(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 5, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 492,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "b4ffd256-7a0d-4289-d481-5d36a7f4684f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.90915\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 493,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "c9397095-d614-471b-b2c6-907d82954e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8895\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 494,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibrJCBno05FR"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 495,
      "metadata": {
        "id": "EwidOIly05FR",
        "outputId": "df3ec516-58c4-47db-c032-26c293629072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjfOqpPx05FS"
      },
      "source": [
        "### Задача №2: Переобучение (Initiation)\n",
        "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
        "\n",
        "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
        "\n",
        "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE2fcyrE05FS"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче.\n",
        "\n",
        "Не используйте `Dropout` и `BatchNorm` в этой задаче"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 543,
      "metadata": {
        "id": "hW8IxBek05FS"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    # self.bn1 = nn.BatchNorm2d(5)\n",
        "    self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    # self.bn2 = nn.BatchNorm2d(10)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(10 * 5 * 5, 6000)\n",
        "    self.fc3 = nn.Linear(6000, 6000)\n",
        "    # self.bn3 = nn.BatchNorm1d(500)\n",
        "    self.fc2 = nn.Linear(6000, 10)\n",
        "\n",
        "    # self.dp = nn.Dropout(0.2)\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 28, 28)\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model_task_2 = MyCNN()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_2.to(device)"
      ],
      "metadata": {
        "id": "6jiORYjA4Pgd",
        "outputId": "b77c7e82-8aa4-433f-ec5b-54d7342ddc1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 544,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=250, out_features=6000, bias=True)\n",
              "  (fc3): Linear(in_features=6000, out_features=6000, bias=True)\n",
              "  (fc2): Linear(in_features=6000, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 544
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 545,
      "metadata": {
        "id": "jprUNz1V05FS",
        "outputId": "52d02d15-46be-49a1-805c-e484c9a4c1c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [500/1875], Loss: 0.4161, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1000/1875], Loss: 0.5069, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1500/1875], Loss: 0.4740, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [500/1875], Loss: 0.4863, Accuracy: 78.12%\n",
            "Epoch [2/5], Step [1000/1875], Loss: 0.4698, Accuracy: 81.25%\n",
            "Epoch [2/5], Step [1500/1875], Loss: 0.3925, Accuracy: 84.38%\n",
            "Epoch [3/5], Step [500/1875], Loss: 0.2717, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1000/1875], Loss: 0.2973, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1500/1875], Loss: 0.3133, Accuracy: 90.62%\n",
            "Epoch [4/5], Step [500/1875], Loss: 0.2471, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1000/1875], Loss: 0.1654, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1500/1875], Loss: 0.1438, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [500/1875], Loss: 0.2493, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1000/1875], Loss: 0.2207, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [1500/1875], Loss: 0.2938, Accuracy: 84.38%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_2.parameters(), lr=0.001)\n",
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_2(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 5, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MAAqZ2805FS"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 546,
      "metadata": {
        "id": "gkkzvGzY05FS"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_2 = []\n",
        "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
        "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
        "    layers_task_2.append(layer_name)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFc0qnUJ05FS"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 547,
      "metadata": {
        "id": "b7uExL-Q05FS",
        "outputId": "59fe23dc-6708-48a4-8d49-92bcafd77337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.91735\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 548,
      "metadata": {
        "id": "wGDdhJ0X05FS",
        "outputId": "5defae15-f004-4085-b107-a5b1d23d0280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8754\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djPttxZ005FS"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 549,
      "metadata": {
        "id": "CxFDi7bk05FT"
      },
      "outputs": [],
      "source": [
        "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
        "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert (\n",
        "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
        "), \"Test accuracy should be at least 0.04 lower that train.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP7Y8HsJ05FT"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 550,
      "metadata": {
        "id": "8Yl3AVBU05FT",
        "outputId": "a6116dc7-0e8d-460c-c0af-866ca61f1109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_tasks_1_and_2.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksa57VFv05FT"
      },
      "source": [
        "### Задача №3: Исправление модели (Return)\n",
        "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
        "\n",
        "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
        "\n",
        "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpHdKXKp05FT"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче.\n",
        "\n",
        "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN9b5Pp405FT"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert (\n",
        "    layers_task_2 is not None\n",
        "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "metadata": {
        "id": "W9ETekkY05FT"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    self.bn1 = nn.BatchNorm2d(5)\n",
        "    self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    self.bn2 = nn.BatchNorm2d(10)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(10 * 5 * 5, 6000)\n",
        "    self.bn3 = nn.BatchNorm1d(6000)\n",
        "    self.fc3 = nn.Linear(6000, 6000)\n",
        "    self.bn4 = nn.BatchNorm1d(6000)\n",
        "    self.fc2 = nn.Linear(6000, 10)\n",
        "\n",
        "    self.dp = nn.Dropout(0.15)\n",
        "    self.dp2d = nn.Dropout2d(0.1)\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 28, 28)\n",
        "    x = self.pool(self.dp2d(F.relu(self.bn1(self.conv1(x)))))\n",
        "    x = self.pool(self.dp2d(F.relu(self.bn2(self.conv2(x)))))\n",
        "    x = self.m(x)\n",
        "    x = self.dp(x)\n",
        "    x = F.relu(self.bn3(self.fc1(x)))\n",
        "    x = self.dp(x)\n",
        "    x = F.relu(self.bn4(self.fc3(x)))\n",
        "    x = self.dp(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model_task_3 = MyCNN()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_3.to(device)"
      ],
      "metadata": {
        "id": "GtWsfUfuG26R",
        "outputId": "5c396559-b6ea-413c-eb93-02c93d5112ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 607,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=250, out_features=6000, bias=True)\n",
              "  (bn3): BatchNorm1d(6000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=6000, out_features=6000, bias=True)\n",
              "  (bn4): BatchNorm1d(6000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=6000, out_features=10, bias=True)\n",
              "  (dp): Dropout(p=0.15, inplace=False)\n",
              "  (dp2d): Dropout2d(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 607
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 608,
      "metadata": {
        "id": "dEayHdKb05FT",
        "outputId": "efdad6fe-f8ef-4907-d4dc-32271439fa12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [500/1875], Loss: 0.4742, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [1000/1875], Loss: 0.5981, Accuracy: 71.88%\n",
            "Epoch [1/5], Step [1500/1875], Loss: 0.3908, Accuracy: 75.00%\n",
            "Epoch [2/5], Step [500/1875], Loss: 0.6476, Accuracy: 75.00%\n",
            "Epoch [2/5], Step [1000/1875], Loss: 0.7132, Accuracy: 71.88%\n",
            "Epoch [2/5], Step [1500/1875], Loss: 0.5616, Accuracy: 78.12%\n",
            "Epoch [3/5], Step [500/1875], Loss: 0.2121, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1000/1875], Loss: 0.4569, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [1500/1875], Loss: 0.6272, Accuracy: 81.25%\n",
            "Epoch [4/5], Step [500/1875], Loss: 0.6333, Accuracy: 78.12%\n",
            "Epoch [4/5], Step [1000/1875], Loss: 0.5588, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [1500/1875], Loss: 0.3570, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [500/1875], Loss: 0.3463, Accuracy: 81.25%\n",
            "Epoch [5/5], Step [1000/1875], Loss: 0.2031, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [1500/1875], Loss: 0.4828, Accuracy: 84.38%\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_3.parameters(), lr=0.001)\n",
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_3(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 5, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W7L12PV05FU"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 609,
      "metadata": {
        "id": "Vs0mGR1105FU"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_3 = []\n",
        "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    layers_task_3.append(layer_name)\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for model_3_layer in layers_task_3:\n",
        "    model_2_layer = layers_task_2[idx]\n",
        "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
        "        assert (\n",
        "            model_3_layer == model_2_layer\n",
        "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
        "        idx += 1\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTJq1ur205FU"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "metadata": {
        "id": "ZGYi48yp05FU",
        "outputId": "1c650303-33e8-485e-c752-f0c69fbef3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.89375\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {
        "id": "n5-2FPQf05FU",
        "outputId": "322cb9c5-3a64-44db-c103-d70311bb46a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.88\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYg1DeJj05FU"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {
        "id": "qHbaPrYn05FU"
      },
      "outputs": [],
      "source": [
        "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert test_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
        "assert (\n",
        "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
        "), \"Test accuracy should not be lower that train more than by 0.015\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SjndVN405FU"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 613,
      "metadata": {
        "id": "nc4ivK1B05FU",
        "outputId": "e4309a4d-2ec3-4015-e8c8-ea0764ec862e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_final.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_final.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xai8JL3tgSq_"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
        "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
        "* `submission_dict_final.json` в задачу Return.\n",
        "\n",
        "\n",
        "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}