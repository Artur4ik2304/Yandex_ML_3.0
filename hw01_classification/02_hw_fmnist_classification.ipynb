{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tq-jL9-_zpAJ"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJgl6TiWzpAK"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PuQP8VKEzpAK",
        "outputId": "4a58add7-4697-4634-9795-953bc95c688c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-12 11:43:38--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-12 11:43:39--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-12 11:43:39 (251 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xkTAGiKdzpAK"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MjOdsX0lzpAL"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "aYcL28OsgSq8",
        "outputId": "a838cf75-fcad-405d-8b43-72c1256fa63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 9.28MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 172kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.12MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 4')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 5, 3)\n",
        "    self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.m = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(10 * 5 * 5, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 1, 28, 28)\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.m(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "model_task_1 = MyCNN()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "9af55c23-2572-410d-ea91-5f62f51dcb0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyCNN(\n",
              "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (m): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=250, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "00471c6a-8026-4665-93b4-5026b84c51bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_data_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        # Прямой запуск\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_task_1(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Обратное распространение и оптимизатор\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Отслеживание точности\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, 5, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ],
      "metadata": {
        "id": "vebjmaiM0pmh",
        "outputId": "d5056549-d4c7-49ff-c74d-e1d5d8b15900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/1875], Loss: 0.5789, Accuracy: 81.25%\n",
            "Epoch [1/5], Step [200/1875], Loss: 0.4109, Accuracy: 81.25%\n",
            "Epoch [1/5], Step [300/1875], Loss: 0.6518, Accuracy: 71.88%\n",
            "Epoch [1/5], Step [400/1875], Loss: 0.5852, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [500/1875], Loss: 0.5554, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [600/1875], Loss: 0.3014, Accuracy: 90.62%\n",
            "Epoch [1/5], Step [700/1875], Loss: 0.3586, Accuracy: 90.62%\n",
            "Epoch [1/5], Step [800/1875], Loss: 0.3822, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [900/1875], Loss: 0.6036, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1000/1875], Loss: 0.4348, Accuracy: 81.25%\n",
            "Epoch [1/5], Step [1100/1875], Loss: 0.5373, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1200/1875], Loss: 0.3498, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1300/1875], Loss: 0.3514, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1400/1875], Loss: 0.5539, Accuracy: 78.12%\n",
            "Epoch [1/5], Step [1500/1875], Loss: 0.2643, Accuracy: 84.38%\n",
            "Epoch [1/5], Step [1600/1875], Loss: 0.2493, Accuracy: 87.50%\n",
            "Epoch [1/5], Step [1700/1875], Loss: 0.8512, Accuracy: 65.62%\n",
            "Epoch [1/5], Step [1800/1875], Loss: 0.3666, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [100/1875], Loss: 0.2857, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [200/1875], Loss: 0.2590, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [300/1875], Loss: 0.3840, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [400/1875], Loss: 0.3473, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [500/1875], Loss: 0.5403, Accuracy: 75.00%\n",
            "Epoch [2/5], Step [600/1875], Loss: 0.2962, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [700/1875], Loss: 0.2320, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [800/1875], Loss: 0.1898, Accuracy: 96.88%\n",
            "Epoch [2/5], Step [900/1875], Loss: 0.6126, Accuracy: 78.12%\n",
            "Epoch [2/5], Step [1000/1875], Loss: 0.4152, Accuracy: 87.50%\n",
            "Epoch [2/5], Step [1100/1875], Loss: 0.1116, Accuracy: 100.00%\n",
            "Epoch [2/5], Step [1200/1875], Loss: 0.3869, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1300/1875], Loss: 0.4745, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [1400/1875], Loss: 0.3373, Accuracy: 93.75%\n",
            "Epoch [2/5], Step [1500/1875], Loss: 0.1704, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [1600/1875], Loss: 0.1649, Accuracy: 96.88%\n",
            "Epoch [2/5], Step [1700/1875], Loss: 0.2330, Accuracy: 90.62%\n",
            "Epoch [2/5], Step [1800/1875], Loss: 0.4140, Accuracy: 84.38%\n",
            "Epoch [3/5], Step [100/1875], Loss: 0.2317, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [200/1875], Loss: 0.3015, Accuracy: 84.38%\n",
            "Epoch [3/5], Step [300/1875], Loss: 0.3749, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [400/1875], Loss: 0.4682, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [500/1875], Loss: 0.4298, Accuracy: 81.25%\n",
            "Epoch [3/5], Step [600/1875], Loss: 0.2614, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [700/1875], Loss: 0.1453, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [800/1875], Loss: 0.3539, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [900/1875], Loss: 0.1473, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1000/1875], Loss: 0.3036, Accuracy: 90.62%\n",
            "Epoch [3/5], Step [1100/1875], Loss: 0.2672, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1200/1875], Loss: 0.6062, Accuracy: 78.12%\n",
            "Epoch [3/5], Step [1300/1875], Loss: 0.3624, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1400/1875], Loss: 0.2042, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1500/1875], Loss: 0.3961, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1600/1875], Loss: 0.2143, Accuracy: 93.75%\n",
            "Epoch [3/5], Step [1700/1875], Loss: 0.3419, Accuracy: 87.50%\n",
            "Epoch [3/5], Step [1800/1875], Loss: 0.2223, Accuracy: 90.62%\n",
            "Epoch [4/5], Step [100/1875], Loss: 0.4450, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [200/1875], Loss: 0.2022, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [300/1875], Loss: 0.1891, Accuracy: 96.88%\n",
            "Epoch [4/5], Step [400/1875], Loss: 0.4033, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [500/1875], Loss: 0.4503, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [600/1875], Loss: 0.3744, Accuracy: 78.12%\n",
            "Epoch [4/5], Step [700/1875], Loss: 0.2048, Accuracy: 96.88%\n",
            "Epoch [4/5], Step [800/1875], Loss: 0.5363, Accuracy: 71.88%\n",
            "Epoch [4/5], Step [900/1875], Loss: 0.2217, Accuracy: 96.88%\n",
            "Epoch [4/5], Step [1000/1875], Loss: 0.0786, Accuracy: 100.00%\n",
            "Epoch [4/5], Step [1100/1875], Loss: 0.2130, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [1200/1875], Loss: 0.1203, Accuracy: 96.88%\n",
            "Epoch [4/5], Step [1300/1875], Loss: 0.2591, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [1400/1875], Loss: 0.1891, Accuracy: 93.75%\n",
            "Epoch [4/5], Step [1500/1875], Loss: 0.3670, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [1600/1875], Loss: 0.2876, Accuracy: 87.50%\n",
            "Epoch [4/5], Step [1700/1875], Loss: 0.2565, Accuracy: 84.38%\n",
            "Epoch [4/5], Step [1800/1875], Loss: 0.3895, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [100/1875], Loss: 0.1048, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [200/1875], Loss: 0.1409, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [300/1875], Loss: 0.2268, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [400/1875], Loss: 0.2095, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [500/1875], Loss: 0.0806, Accuracy: 100.00%\n",
            "Epoch [5/5], Step [600/1875], Loss: 0.2941, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [700/1875], Loss: 0.2476, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [800/1875], Loss: 0.1728, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [900/1875], Loss: 0.4022, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1000/1875], Loss: 0.7599, Accuracy: 78.12%\n",
            "Epoch [5/5], Step [1100/1875], Loss: 0.1427, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1200/1875], Loss: 0.2390, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1300/1875], Loss: 0.2441, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [1400/1875], Loss: 0.1641, Accuracy: 93.75%\n",
            "Epoch [5/5], Step [1500/1875], Loss: 0.4010, Accuracy: 87.50%\n",
            "Epoch [5/5], Step [1600/1875], Loss: 0.3520, Accuracy: 90.62%\n",
            "Epoch [5/5], Step [1700/1875], Loss: 0.4498, Accuracy: 84.38%\n",
            "Epoch [5/5], Step [1800/1875], Loss: 0.3014, Accuracy: 90.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "d63d269b-f278-40e9-8544-04bff66a0224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.91005\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "ea3db9bd-098b-4495-dc6d-898d7de5952c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8871\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfGLYkYzpAO"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M_DMqDnvzpAO",
        "outputId": "fce51a71-f331-4ae5-cb7b-69d3d230eaa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0xWRUcizpAP"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}